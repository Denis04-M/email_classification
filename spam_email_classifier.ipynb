{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spam_email_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM2n/gZgSV4CDHSCYqk3bv/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Denis04-M/email_classification/blob/main/spam_email_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvNscwEKuRoG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03079a67-4650-4e88-eeb5-66c19beacabc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "filepath1 = '/content/drive/MyDrive/data/enron1/ham/'\n",
        "filepath2 = '/content/drive/MyDrive/data/enron1/spam/'\n",
        "\n",
        "emails, labels = [], []\n",
        "\n",
        "# appending valid emails into emails[]\n",
        "for filename in glob.glob(os.path.join(filepath1, '*.txt')):\n",
        "  with open(filename, 'r', encoding='ISO-8859-1') as email_file:\n",
        "    emails.append(email_file.read())\n",
        "    labels.append(1) # labeling each valid email as 1\n",
        "\n",
        "# appending spam emails into emils[]\n",
        "for filename in glob.glob(os.path.join(filepath2, '*.txt')):\n",
        "  with open(filename, 'r', encoding='ISO-8859-1') as email_file:\n",
        "    emails.append(email_file.read())\n",
        "    labels.append(0) # labeling each spam email as 0\n",
        "\n",
        "print(len(emails))\n",
        "print(len(labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7VwEuty7jIL",
        "outputId": "7f679cb3-8204-4537-db90-07054b90e314"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5172\n",
            "5172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import names\n",
        "import nltk\n",
        "from  nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# nltk.download('names')\n",
        "# nltk.download('wordnet')\n",
        "# nltk.download('omw-1.4')\n",
        "\n",
        "people_names = set(names.words())\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# function to remove numbers and special characters\n",
        "def letters_only(astr):\n",
        "  return astr.isalpha()\n",
        "\n",
        "# cleaning the data (removin)\n",
        "def cleanText(docs):\n",
        "  cleaned_docs = []\n",
        "  for doc in docs:\n",
        "    cleaned_docs.append(\" \".join([lemmatizer.lemmatize(word.lower())\n",
        "      for word in doc.split()\n",
        "        if letters_only(word) and word not in people_names]))\n",
        "  return cleaned_docs\n",
        "\n",
        "cleaned_emails = cleanText(emails)\n",
        "\n",
        "print(cleaned_emails[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwZgY8mhCo_Z",
        "outputId": "f979d0e1-f4c7-4680-fc68-84228470fb62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tried to get fancy with your address and it came back to me forwarded by lauri a allen hol aepin on pm to daren farmer enron com cc subject daren your rate for meter highlander central point for year starting delivered to equistar channelview is mm that price expires in week on november let me know if you need me to refresh after that time thanks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from collections import defaultdict\n",
        "\n",
        "cv = CountVectorizer(stop_words = 'english', max_features=500)\n",
        "\n",
        "term_docs = cv.fit_transform(cleaned_emails)\n",
        "\n",
        "def get_label_index(labels):\n",
        "  label_index = defaultdict(list)\n",
        "  for index, label in enumerate(labels):\n",
        "    label_index[label].append(index)\n",
        "  return label_index\n",
        "\n",
        "label_index = get_label_index(labels)\n",
        "\n",
        "def get_prior(label_index):\n",
        "  prior = {label: len(index) for label, index in label_index.items()}\n",
        "  total_count = sum(prior.values())\n",
        "  for label in prior:\n",
        "    prior[label] /= float(total_count)\n",
        "  return prior\n",
        "\n",
        "prior = get_prior(label_index)\n",
        "print(prior)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQ5GTYABBzuZ",
        "outputId": "1311af25-98ef-47d4-c5f0-f2446ce4a253"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 0.7099767981438515, 0: 0.2900232018561485}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_likelihood(term_document_matrix, label_index, smoothing = 0):\n",
        "  likelihood = {}\n",
        "  for label, index in label_index.items():\n",
        "    likelihood[label] = term_document_matrix[index, :].sum(axis=0) + smoothing\n",
        "    likelihood[label] = np.asarray(likelihood[label])[0]\n",
        "    total_count = likelihood[label].sum()\n",
        "    likelihood[label] = likelihood[label] / float(total_count)\n",
        "  return likelihood\n",
        "\n",
        "smoothing = 1\n",
        "likelihood = get_likelihood(term_docs, label_index, smoothing)\n",
        "\n",
        "print(likelihood[1][:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7b8XsSobLwL",
        "outputId": "bc0b88f3-b364-4483-a9d3-590c24482d38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.00108581 0.00095774 0.00087978 0.00084637 0.00010023]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_posterior(term_document_matrix, prior, likelihood):\n",
        "  num_docs = term_document_matrix.shape[0]\n",
        "  posteriors = []\n",
        "  for i in range(num_docs):\n",
        "    posterior = {key: np.log(prior_label)\n",
        "      for key, prior_label in prior.items()}\n",
        "    for label, likelihood_label in likelihood.items():\n",
        "      term_document_vector = term_document_matrix.getrow(i)\n",
        "    counts = term_document_vector.data\n",
        "    indices = term_document_vector.indices\n",
        "    for count, index in zip(counts, indices):\n",
        "      posterior[label] += np.log(likelihood_label[index]) * count\n",
        "      min_log_posterior = min(posterior.values())\n",
        "    for label in posterior:\n",
        "      try:\n",
        "        posterior[label] = np.exp(posterior[label] - min_log_posterior)\n",
        "      \n",
        "      except:\n",
        "        posterior[label] = float('inf')\n",
        "    sum_posterior = sum(posterior.values())\n",
        "    for label in posterior:\n",
        "      if posterior[label] == float('inf'):\n",
        "        posterior[label] = 1.0\n",
        "      else:\n",
        "        posterior[label] /= sum_posterior\n",
        "      posteriors.append(posterior.copy())\n",
        "  return posteriors"
      ],
      "metadata": {
        "id": "TTlmbCEHYdmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "e_mails_test = ['''Subject: flat screens\n",
        "               Hello,\n",
        "               please call or contact regarding the other flat screens requested .\n",
        "               trisha tlapek - eb 3132 b\n",
        "               michael sergeev - eb 3132 a\n",
        "               also the sun blocker that was taken away from eb 3131 a .\n",
        "               trisha should two monitors also michael .\n",
        "               thanks\n",
        "               kevin moore''',\n",
        "                '''Subject: having problems in bed ? we can help !\n",
        "                cialis allows men to enjoy a fully normal sex life without\n",
        "                having to plan the sexual act .\n",
        "                if we let things terrify us, life will not be worth living\n",
        "                brevity is the soul of lingerie .\n",
        "                suspicion always haunts the guilty mind .''']\n",
        "\n",
        "cleaned_test = cleanText(e_mails_test)\n",
        "term_docs_test = cv.transform(cleaned_test)\n",
        "posterior = get_posterior(term_docs_test, prior, likelihood)\n",
        "print(posterior)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1I1LF9g3zxVj",
        "outputId": "4314c598-94b4-4cef-c646-b60bda0e8b95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{1: 1.0, 0: 1.0}, {1: 1.0, 0: 1.859490872529796e-18}, {1: 1.0, 0: 1.0}, {1: 1.0, 0: 5.617000906353728e-25}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(cleaned_emails, labels, random_state = 42)\n",
        "term_docs_train = cv.fit_transform(X_train)\n",
        "label_index = get_label_index(y_train)\n",
        "prior = get_prior(label_index)\n",
        "likelihood = get_likelihood(term_docs_train, label_index, smoothing)\n",
        "term_docs_test = cv.transform(X_test)\n",
        "posterior = get_posterior(term_docs_test, prior, likelihood)\n",
        "correct = 0.0\n",
        "for pred, actual in zip(posterior, y_test):\n",
        "  if actual == 1:\n",
        "    if pred[1] >= 0.5:\n",
        "      correct += 1\n",
        "  elif pred[0] > 0.5:\n",
        "    correct += 1\n",
        "\n",
        "print('The accuracy on {0} testing samples is:{1:.1f}%'.format(len(y_test), correct/len(y_test)*100))"
      ],
      "metadata": {
        "id": "VrNUDPFm2zuO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "486901db-858a-41d1-f9e6-6ca5a2c112a8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy on 1293 testing samples is:64.0%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: overflow encountered in exp\n",
            "  app.launch_new_instance()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "clf = MultinomialNB(alpha=1.0, fit_prior=True)\n",
        "clf.fit(term_docs_train, y_train)\n",
        "prediction_prob = clf.predict_proba(term_docs_test)\n",
        "prediction_prob[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_7sceEG8tZk",
        "outputId": "10b64fd9-9b43-4590-a720-367ff069a9dd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.46877274e-007, 9.99999853e-001],\n",
              "       [1.57257306e-019, 1.00000000e+000],\n",
              "       [3.17877195e-017, 1.00000000e+000],\n",
              "       [5.00804442e-020, 1.00000000e+000],\n",
              "       [1.85530452e-021, 1.00000000e+000],\n",
              "       [4.61941897e-039, 1.00000000e+000],\n",
              "       [6.10560689e-106, 1.00000000e+000],\n",
              "       [1.00000000e+000, 4.00769888e-012],\n",
              "       [1.22570208e-025, 1.00000000e+000],\n",
              "       [4.12623637e-014, 1.00000000e+000]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = clf.predict(term_docs_test)\n",
        "prediction[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SY713fNR9Rgi",
        "outputId": "59b859f3-cc9e-43d5-eeef-cd9ccda07b8a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = clf.score(term_docs_test, y_test)\n",
        "print('The accuracy using MultinomialNB is:{0:.1f}%'.format(accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28rdGp5g9csV",
        "outputId": "ce44653d-8620-46ee-b623-23eb9a8b22ec"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy using MultinomialNB is:91.0%\n"
          ]
        }
      ]
    }
  ]
}